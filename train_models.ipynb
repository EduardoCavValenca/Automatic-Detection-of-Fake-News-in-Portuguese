{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pre_processed_path = os.path.join('data', 'csvs', \"pre_processed.csv\")\n",
    "# pre_normalized_path = os.path.join('data', 'csvs', \"pre_normalized.csv\")\n",
    "news_validation_path = os.path.join('data', 'csvs', \"news_validation.csv\")\n",
    "covid_validation_path = os.path.join('data', 'csvs', \"covid.csv\")\n",
    "\n",
    "data_frame_paths = [pre_processed_path]\n",
    "data_frame_names = [\"pre_processed\"]\n",
    "\n",
    "validations_paths = [news_validation_path, covid_validation_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def add_vectorizer(codes):\n",
    "    vectorizers = []\n",
    "    vectorizers_names = []\n",
    "\n",
    "    for code in codes:\n",
    "        add_code = \"_max\" if code == 0 else (\"_\" + str(code))\n",
    "\n",
    "        if code == 0:\n",
    "            filtered_vocab = None\n",
    "        else:\n",
    "            filtered_vocab_path = os.path.join('data', 'vocabularies', \"filtered_vocab_\" + str(code) + \".csv\")\n",
    "            filtered_vocab = pd.read_csv(filtered_vocab_path).set_index('word').to_dict()['index']\n",
    "\n",
    "        vectorizer = CountVectorizer(strip_accents=\"ascii\", lowercase=True, vocabulary=filtered_vocab)\n",
    "        vectorizer_norm = TfidfVectorizer(strip_accents=\"ascii\", lowercase=True, vocabulary=filtered_vocab, use_idf = False, norm='l2')\n",
    "        vectorizer_idf = TfidfVectorizer(strip_accents=\"ascii\", lowercase=True, vocabulary=filtered_vocab)\n",
    "\n",
    "        vectorizers += [vectorizer, vectorizer_norm, vectorizer_idf]\n",
    "        vectorizers_names += [\"CountVectorizer\" + add_code, \"TfidfVectorizer_norm\" + add_code, \"TfidfVectorizer_idf\" + add_code]\n",
    "\n",
    "    return vectorizers, vectorizers_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers, vectorizers_names = add_vectorizer([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "algs = []\n",
    "algs_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "Gaussain_NB = GaussianNB()\n",
    "Bernoulli_NB = BernoulliNB()\n",
    "Multinomial_NB = MultinomialNB()\n",
    "\n",
    "algs += [Gaussain_NB, Bernoulli_NB, Multinomial_NB]\n",
    "algs_names += [\"Gaussain_NB\", \"Bernoulli_NB\", \"Multinomial_NB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "Decision_Tree_Classifier = DecisionTreeClassifier()\n",
    "Extra_Tree_Classifier = ExtraTreeClassifier()\n",
    "Random_Forest_Classifier = RandomForestClassifier()\n",
    "Extra_Trees_Classifier = ExtraTreesClassifier()\n",
    "\n",
    "algs += [Decision_Tree_Classifier, Extra_Tree_Classifier, Random_Forest_Classifier, Extra_Trees_Classifier]\n",
    "algs_names += [\"Decision_Tree_Classifier\", \"Extra_Tree_Classifier\", \"Random_Forest_Classifier\", \"Extra_Trees_Classifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "\n",
    "algs += [knn, svc]\n",
    "algs_names += [\"KNN\", \"SVC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "AdaBoost = AdaBoostClassifier()\n",
    "GradientBoost = GradientBoostingClassifier()\n",
    "\n",
    "algs += [AdaBoost, GradientBoost]\n",
    "algs_names += [\"AdaBoost\", \"GradientBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "LGBM = LGBMClassifier()\n",
    "CatBoost = CatBoostClassifier()\n",
    "\n",
    "algs += [LGBM, CatBoost]\n",
    "algs_names += [\"LGBM\", \"CatBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(max_iter=1000)\n",
    "\n",
    "algs += [mlp]\n",
    "algs_names += [\"MLP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import train\n",
    "\n",
    "sys.path.append( '.' )\n",
    "importlib.reload(train)\n",
    "\n",
    "df = train.get_result_data_frames(algs, algs_names, vectorizers, vectorizers_names, data_frame_paths, data_frame_names, validations_paths)\n",
    "df = df.sort_values(by=['algorithm',\"accuracy\"], ascending=[True, False]).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>dataset</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>custom_accuracy</th>\n",
       "      <th>covid_accuracy</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>pre_processed</td>\n",
       "      <td>TfidfVectorizer_idf_4096</td>\n",
       "      <td>0.9611</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>0.9612</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>228.53</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random_Forest_Classifier</td>\n",
       "      <td>pre_processed</td>\n",
       "      <td>TfidfVectorizer_idf_4096</td>\n",
       "      <td>0.9611</td>\n",
       "      <td>0.9631</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extra_Trees_Classifier</td>\n",
       "      <td>pre_processed</td>\n",
       "      <td>CountVectorizer_4096</td>\n",
       "      <td>0.9606</td>\n",
       "      <td>0.9563</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.9611</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>18.57</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>pre_processed</td>\n",
       "      <td>CountVectorizer_4096</td>\n",
       "      <td>0.9606</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>12.35</td>\n",
       "      <td>11.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extra_Trees_Classifier</td>\n",
       "      <td>pre_processed</td>\n",
       "      <td>CountVectorizer_1024</td>\n",
       "      <td>0.9602</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>6.23</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>KNN</td>\n",
       "      <td>pre_processed</td>\n",
       "      <td>CountVectorizer_1024</td>\n",
       "      <td>0.7491</td>\n",
       "      <td>0.6677</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>0.8001</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>KNN</td>\n",
       "      <td>pre_processed</td>\n",
       "      <td>TfidfVectorizer_norm_1024</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.9415</td>\n",
       "      <td>0.5032</td>\n",
       "      <td>0.6559</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>KNN</td>\n",
       "      <td>pre_processed</td>\n",
       "      <td>TfidfVectorizer_idf_4096</td>\n",
       "      <td>0.7282</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>KNN</td>\n",
       "      <td>pre_processed</td>\n",
       "      <td>CountVectorizer_4096</td>\n",
       "      <td>0.7019</td>\n",
       "      <td>0.6281</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.7713</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>KNN</td>\n",
       "      <td>pre_processed</td>\n",
       "      <td>TfidfVectorizer_norm_4096</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.4103</td>\n",
       "      <td>0.5696</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    algorithm        dataset                 vectorizer  \\\n",
       "0                    CatBoost  pre_processed   TfidfVectorizer_idf_4096   \n",
       "1    Random_Forest_Classifier  pre_processed   TfidfVectorizer_idf_4096   \n",
       "2      Extra_Trees_Classifier  pre_processed       CountVectorizer_4096   \n",
       "3                         SVC  pre_processed       CountVectorizer_4096   \n",
       "4      Extra_Trees_Classifier  pre_processed       CountVectorizer_1024   \n",
       "..                        ...            ...                        ...   \n",
       "121                       KNN  pre_processed       CountVectorizer_1024   \n",
       "122                       KNN  pre_processed  TfidfVectorizer_norm_1024   \n",
       "123                       KNN  pre_processed   TfidfVectorizer_idf_4096   \n",
       "124                       KNN  pre_processed       CountVectorizer_4096   \n",
       "125                       KNN  pre_processed  TfidfVectorizer_norm_4096   \n",
       "\n",
       "     accuracy  precision  recall      f1  custom_accuracy  covid_accuracy  \\\n",
       "0      0.9611     0.9656  0.9568  0.9612           0.5000          0.5333   \n",
       "1      0.9611     0.9631  0.9595  0.9613           0.5000          0.5000   \n",
       "2      0.9606     0.9563  0.9660  0.9611           0.5000          0.5000   \n",
       "3      0.9606     0.9605  0.9614  0.9609           0.5714          0.5000   \n",
       "4      0.9602     0.9613  0.9595  0.9604           0.5714          0.5000   \n",
       "..        ...        ...     ...     ...              ...             ...   \n",
       "121    0.7491     0.6677  0.9982  0.8001           0.5000          0.5000   \n",
       "122    0.7343     0.9415  0.5032  0.6559           0.6429          0.4667   \n",
       "123    0.7282     0.8846  0.5290  0.6621           0.6429          0.6333   \n",
       "124    0.7019     0.6281  0.9991  0.7713           0.5000          0.5000   \n",
       "125    0.6880     0.9311  0.4103  0.5696           0.7143          0.5667   \n",
       "\n",
       "     train_time  predict_time  \n",
       "0        228.53          2.19  \n",
       "1          7.25          0.11  \n",
       "2         18.57          0.14  \n",
       "3         12.35         11.74  \n",
       "4          6.23          0.09  \n",
       "..          ...           ...  \n",
       "121        0.00          0.52  \n",
       "122        0.01          0.39  \n",
       "123        0.05          1.07  \n",
       "124        0.01          1.26  \n",
       "125        0.04          1.08  \n",
       "\n",
       "[126 rows x 11 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=[\"accuracy\"], ascending=[False]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results/pre_max.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
