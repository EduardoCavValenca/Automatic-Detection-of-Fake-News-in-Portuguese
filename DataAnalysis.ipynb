{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the preprocessed data\n",
    "import os\n",
    "\n",
    "pre_file_path = os.path.join('preprocessed', 'pre-processed.csv')\n",
    "pre_df = pd.read_csv(pre_file_path, index_col= 0)\n",
    "pre_df.index.name = None\n",
    "pre_df = pre_df.rename(columns={\"preprocessed_news\": \"text\"})\n",
    "pre_df = pre_df[[\"text\",\"label\"]]\n",
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into fake and true news\n",
    "fake_df = pre_df[pre_df[\"label\"] == 'fake']\n",
    "true_df = pre_df[pre_df[\"label\"] == 'true']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag of words for each df\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "fake_bag = CountVectorizer().fit(fake_df[\"text\"])\n",
    "true_bag = CountVectorizer().fit(true_df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_bag = fake_bag.vocabulary_\n",
    "true_bag = true_bag.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bag of words with the difference between the two\n",
    "\n",
    "# Get all words from both bags\n",
    "all_words = set(list(fake_bag.keys()) + list(true_bag.keys()))\n",
    "\n",
    "bag = {}\n",
    "for word in all_words:\n",
    "    if word in fake_bag and word in true_bag:\n",
    "        bag[word] = true_bag[word] - fake_bag[word]\n",
    "    elif word in fake_bag:\n",
    "        bag[word] = -fake_bag[word]\n",
    "    else:\n",
    "        bag[word] = true_bag[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_to_best = sorted(bag.items(), key= lambda x: x[1])\n",
    "worst_to_best[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(worst_to_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words in each bag\n",
    "len(fake_bag), len(true_bag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfFakeWords = sum(fake_bag.values())\n",
    "numberOfTrueWords = sum(true_bag.values())\n",
    "numberOfWords = numberOfFakeWords + numberOfTrueWords\n",
    "print(numberOfFakeWords / numberOfWords, numberOfTrueWords / numberOfWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_df = pd.DataFrame(bag.values(), columns=[\"Rate\"])\n",
    "distribution_df\n",
    "\n",
    "# Create a histogram of the distribution\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(distribution_df[\"Rate\"], bins=100, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_fake_bag = {}\n",
    "for word in fake_bag:\n",
    "    normalized_fake_bag[word] = fake_bag[word] / numberOfFakeWords\n",
    "\n",
    "normalized_true_bag = {}\n",
    "for word in true_bag:\n",
    "    normalized_true_bag[word] = true_bag[word] / numberOfTrueWords\n",
    "\n",
    "normalized_bag = {}\n",
    "for word in all_words:\n",
    "    if word in normalized_fake_bag and word in normalized_true_bag:\n",
    "        normalized_bag[word] = normalized_true_bag[word] - normalized_fake_bag[word]\n",
    "    elif word in fake_bag:\n",
    "        normalized_bag[word] = -normalized_fake_bag[word]\n",
    "    else:\n",
    "        normalized_bag[word] = normalized_true_bag[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_df = pd.DataFrame(normalized_bag.items(), columns=[\"Word\", \"Rate\"])\n",
    "distribution_df\n",
    "\n",
    "# Create a histogram of the distribution\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(distribution_df[\"Rate\"], bins=100, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_words_df = distribution_df.loc[distribution_df[\"Rate\"] < -5 * 1e-5]\n",
    "worst_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_worst_word =  worst_words_df[\"Word\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the words are in the fake news\n",
    "countFake = 0\n",
    "for text in fake_df[\"text\"].values:\n",
    "    for fakeWord in check_worst_word:\n",
    "        if fakeWord in text:\n",
    "            countFake += 1\n",
    "\n",
    "\n",
    "countTrue = 0\n",
    "for text in true_df[\"text\"].values:\n",
    "    for fakeWord in check_worst_word:\n",
    "        if fakeWord in text:\n",
    "            countTrue += 1\n",
    "\n",
    "countFake, countTrue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(countFake / numberOfFakeWords, countTrue / numberOfTrueWords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fake_bag.keys()), len(true_bag.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfFakeWords/numberOfTrueWords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
